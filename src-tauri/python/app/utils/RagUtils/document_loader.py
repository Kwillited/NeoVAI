"""æ–‡æ¡£åŠ è½½å·¥å…·æ¨¡å— - æä¾›ç»Ÿä¸€çš„æ–‡æ¡£åŠ è½½æ¥å£"""
import os
import time
from typing import List, Dict, Any
from langchain_community.document_loaders import (
    TextLoader, PyPDFLoader, Docx2txtLoader, DirectoryLoader
)

class DocumentLoader:
    """æ–‡æ¡£åŠ è½½å™¨ç±» - å¤„ç†å„ç§æ ¼å¼æ–‡æ¡£çš„åŠ è½½"""
    
    # æ”¯æŒçš„æ–‡ä»¶æ‰©å±•ååŠå…¶å¯¹åº”çš„åŠ è½½å™¨
    SUPPORTED_EXTENSIONS = {
        'txt': TextLoader,
        'pdf': PyPDFLoader,
        'doc': Docx2txtLoader,
        'docx': Docx2txtLoader
    }
    
    # æ–‡æ¡£ç¼“å­˜ï¼Œæ ¼å¼: {file_path: (mtime, document_info)}  
    _cache = {}
    # ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
    _CACHE_EXPIRY = 300  # 5åˆ†é’Ÿ
    
    @staticmethod
    def load_document(file_path: str) -> Dict[str, Any]:
        """åŠ è½½æ–‡æ¡£å¹¶è¿”å›æ–‡æ¡£ä¿¡æ¯
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            Dict: åŒ…å«æ–‡æ¡£å†…å®¹å’Œå…ƒä¿¡æ¯çš„å­—å…¸
        """
        # æ£€æŸ¥ç¼“å­˜
        current_mtime = os.path.getmtime(file_path)
        
        # æ£€æŸ¥ç¼“å­˜ä¸­æ˜¯å¦æœ‰è¯¥æ–‡ä»¶ï¼Œä¸”æœªè¿‡æœŸï¼Œä¸”æ–‡ä»¶æœªä¿®æ”¹
        if file_path in DocumentLoader._cache:
            cached_mtime, cached_info, cached_timestamp = DocumentLoader._cache[file_path]
            if cached_mtime == current_mtime and (time.time() - cached_timestamp) < DocumentLoader._CACHE_EXPIRY:
                print(f"ğŸ“¦ ä½¿ç”¨ç¼“å­˜çš„æ–‡æ¡£: {os.path.basename(file_path)}")
                return cached_info
        
        documents = []
        file_extension = file_path.rsplit('.', 1)[1].lower() if '.' in file_path else ''
        
        try:
            # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©åˆé€‚çš„åŠ è½½å™¨
            if file_extension in DocumentLoader.SUPPORTED_EXTENSIONS:
                loader_class = DocumentLoader.SUPPORTED_EXTENSIONS[file_extension]
                
                # TextLoaderéœ€è¦æŒ‡å®šç¼–ç 
                if file_extension == 'txt':
                    loader = loader_class(file_path, encoding='utf-8')
                else:
                    loader = loader_class(file_path)
                
                documents = loader.load()
            
            # è®°å½•æ–‡æ¡£ä¿¡æ¯
            document_info = {
                'total_docs': len(documents),
                'page_count': sum(1 for doc in documents) if documents else 0,
                'file_path': file_path,
                'file_extension': file_extension
            }
            
            # å¦‚æœæœ‰æ–‡æ¡£ï¼Œæ·»åŠ ä¸€äº›åŸºæœ¬ä¿¡æ¯
            if documents:
                first_doc = documents[0]
                document_info['first_page_content_length'] = len(first_doc.page_content)
                document_info['metadata'] = first_doc.metadata
                document_info['documents'] = documents
            
            # ç¼“å­˜ç»“æœ
            DocumentLoader._cache[file_path] = (current_mtime, document_info, time.time())
            print(f"ğŸ“„ åŠ è½½æ–‡æ¡£: {os.path.basename(file_path)}")
            
        except Exception as e:
            document_info = {
                'error': str(e),
                'total_docs': 0,
                'page_count': 0,
                'file_path': file_path,
                'file_extension': file_extension
            }
            # é”™è¯¯ä¿¡æ¯ä¹Ÿç¼“å­˜
            DocumentLoader._cache[file_path] = (current_mtime, document_info, time.time())
        
        return document_info
    
    @staticmethod
    def load_directory(directory_path: str, recursive: bool = True) -> List[Dict[str, Any]]:
        """ä½¿ç”¨LangChain DirectoryLoaderåŠ è½½æ•´ä¸ªç›®å½•çš„æ–‡æ¡£
        
        Args:
            directory_path: ç›®å½•è·¯å¾„
            recursive: æ˜¯å¦é€’å½’åŠ è½½å­ç›®å½•
            
        Returns:
            List[Dict]: åŒ…å«æ‰€æœ‰æ–‡æ¡£ä¿¡æ¯çš„å­—å…¸åˆ—è¡¨
        """
        print(f"ğŸ“ å¼€å§‹åŠ è½½ç›®å½•: {directory_path}")
        
        # åˆ›å»ºç›®å½•åŠ è½½å™¨
        loader = DirectoryLoader(
            path=directory_path,
            glob="**/*.{txt,pdf,doc,docx}" if recursive else "*.{txt,pdf,doc,docx}",
            show_progress=True
        )
        
        # åŠ è½½æ‰€æœ‰æ–‡æ¡£
        documents = loader.load()
        print(f"âœ… ç›®å½•åŠ è½½å®Œæˆï¼Œå…±åŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£")
        
        # è½¬æ¢ä¸ºç»Ÿä¸€çš„æ–‡æ¡£ä¿¡æ¯æ ¼å¼
        result = []
        for i, doc in enumerate(documents):
            file_path = doc.metadata.get('source', f"file_{i}")
            file_extension = os.path.splitext(file_path)[1].lower().lstrip('.') if '.' in file_path else ''
            
            document_info = {
                'total_docs': 1,
                'page_count': 1,
                'file_path': file_path,
                'file_extension': file_extension,
                'first_page_content_length': len(doc.page_content),
                'metadata': doc.metadata,
                'documents': [doc]
            }
            
            result.append(document_info)
        
        return result
    
    @staticmethod
    def clear_cache() -> None:
        """æ¸…é™¤æ‰€æœ‰ç¼“å­˜çš„æ–‡æ¡£ä¿¡æ¯"""
        DocumentLoader._cache.clear()
        print(f"ğŸ—‘ï¸  å·²æ¸…é™¤æ‰€æœ‰æ–‡æ¡£ç¼“å­˜")
    
    @staticmethod
    def remove_from_cache(file_path: str) -> None:
        """ä»ç¼“å­˜ä¸­ç§»é™¤æŒ‡å®šæ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
        """
        if file_path in DocumentLoader._cache:
            del DocumentLoader._cache[file_path]
            print(f"ğŸ—‘ï¸  å·²ä»ç¼“å­˜ä¸­ç§»é™¤æ–‡ä»¶: {os.path.basename(file_path)}")
    
    @staticmethod
    def get_supported_extensions() -> List[str]:
        """è·å–æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å
        
        Returns:
            List[str]: æ”¯æŒçš„æ–‡ä»¶æ‰©å±•ååˆ—è¡¨
        """
        return list(DocumentLoader.SUPPORTED_EXTENSIONS.keys())